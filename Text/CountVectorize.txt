from sklearn.feature_extraction.text import CountVectorizer
 
document = ["One Geek helps Two Geeks",
            "Two Geeks help Four Geeks",
            "Each Geek helps many other Geeks at GeeksforGeeks"]
 
# Create a Vectorizer Object
vectorizer = CountVectorizer()
 
vectorizer.fit(document)
 
# Printing the identified Unique words along with their indices
print("Vocabulary: ", vectorizer.vocabulary_)
 
# Encode the Document
vector = vectorizer.transform(document)
 
# Summarizing the Encoded Texts
print("Encoded Document is:")
print(vector.toarray())





---------------------------------------------------------------------
Vocabulary:  {'one': 9, 'geek': 3, 'helps': 7, 'two': 11, 'geeks': 4, 'help': 6, 'four': 2, 'each': 1, 'many': 8, 'other': 10, 'at': 0, 'geeksforgeeks': 5}

Encoded Document is:

[ [0 0 0 1 1 0 0 1 0 1 0 1]

  [0 0 1 0 2 0 1 0 0 0 0 1]

  [1 1 0 1 1 1 0 1 1 0 1 0] ]

--------------------------------------------------------------------------
knn gen vecini, nu e de memorat
naive bayse -> sa stim ce inseamna multinominal 
svm -> ce e svm liniar, cum imparte el, kernel liniar sau rbf cum arata, ce e C



confussion matrix -> ce inseamna , parametrii
ce este acuratetea, cum se calculaeza
recol
precizie
preprocezare
language detection



-------------------------------------------------------------------------
knn -> vede ce spun vecinii
sa ne inspiram din ce afce knn pentru mai mai multe metode

------------------------------------------------------------------------
caracteristici -> cum preprocesam textul
parametrii hipeparametrii : vecini, kenrnel, C chestii de genul
cum sunt antrenati parametrii
cum dureaza antrenarea : of, necazuri
performanta : pe kaggle am obtinut
1 model : matricea de confuzie asociata

->>>> orice chestie in plus este apreciata : de facut grafic cu datele de antrenament

--------------------------------------------------------------------------
la retele sa ne uitam bine la functii ca ne da la examen


---------------------------------------------------------------------------
mlp de incercat
collab cu GP

solver -> adam e cel mai bun
la numarul de straturi de modificat
learning rate
nr max de iteratii -> adica numarul de epoci
MMMMLLLLLLPPPPP

